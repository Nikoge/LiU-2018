---
title: "732A99 chetabook"
author: "Anubhav Dikshit(anudi287)"
date: "26 November 2018"
output: 
    pdf_document:
      toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 2016

## Assignment1

### 1. Divide the dataset into training and test sets (80/20), use seed 12345. Fit a decision tree with default settings to the training data and plot the resulting tree. Finally, remove the second observation from the training data, fit the tree model again and plot the tree. Compare the trees and comment why the tree structure changed so much although only one observation is deleted.

```{r}

library(tree)

set.seed(12345)

data <- read.csv("crx.csv", header = TRUE)
data$Class <- as.factor(data$Class)

# 50-50 split
n=nrow(data)
id=sample(1:n, floor(n*0.8))
train=data[id,]
test=data[-id,]

decision_tree <- tree(data = train, formula = Class~.)
train_new <- train[-2,]
decision_tree_new <- tree(data = train_new, formula = Class~., method = "class")

plot(decision_tree, main= "Original decision tree")
text(decision_tree)
plot(decision_tree_new, main= "Modified decision tree")
text(decision_tree_new)
```

### 2.Prune the tree fitted to the training data by using the cross-validation. Provide a cross-validation plot and comment how many leaves the optimal tree should have. Which variables were selected by the tree?
```{r}
library(ggplot2)

set.seed(12345)

cv_tree <- cv.tree(decision_tree, FUN = prune.tree, K = 10)
df_result <- as.data.frame(cbind(size = cv_tree$size, dev = cv_tree$dev))
ggplot(df_result, aes(x = size, y = dev)) + geom_point() + geom_line()

# puring the tree for leaf size of 3
best_tree <- prune.tree(decision_tree, best = 2)
plot(best_tree, main="Pruned Tree for the given dataset")
text(best_tree)
```

### 3.Fit a GAM model with features A3 and A9, comment on the choice of family parameter. Why is it pointless to include a spline component of A9? Provide an equation of the fitted model. Comment which components are significant. Plot the spline component of A3 and interpret the plot.

```{r}
set.seed(12345)
library(mgcv)

gam_model <- mgcv::gam(data=train, formula = Class~s(A3)+A9, family=binomial)
summary(gam_model)
plot(gam_model)

```

### 4.Use the following error function to compute the test error for the GAM and tree models: E = sum((Ylogp) + (1-Y)log(1-p)) where Y and p refer to Y=1. Which model is the best according to this criterion? Why is this criterion sometimes more reasonable to use than the misclassification rate?

```{r}
predicted_test <- predict.gam(gam_model, newdata = test, type="response")
predicted_test <- as.data.frame(predicted_test)
predicted_test$actual_value <- as.numeric(as.character(test$Class))
predicted_test$predicted_class <- ifelse(predicted_test$predicted_test >0.5, 1, 0)


predicted_test$error <- (predicted_test$predicted_class * log(predicted_test$predicted_test)) + ((1-predicted_test$predicted_class)*log(1-predicted_test$predicted_test))

sum(predicted_test$error)

```

## Assignment 2

### 1.Interpret the plot resulting from the code below.
```{r}
library(mboost)
bf <- read.csv2("bodyfatregression.csv")
set.seed(1234567890)
m <- blackboost(Bodyfat_percent~Waist_cm+Weight_kg, data=bf)
mstop(m)
cvf <- cv(model.weights(m), type="kfold")
cvm <- cvrisk(m, folds=cvf, grid=1:100)
plot(cvm)
mstop(cvm)

```

### In the following steps, you are asked to use the R package kernlab to learn a SVM for classifying the spam dataset that is included with the package. For the C parameter, consider values 1 and 5. Consider the radial basis function kernel (also known as Gaussian) and the linear kernel. For the former, consider a width of 0.01 and 0.05. This implies that you have to select among six models.
```{r}
library(kernlab)

data(spam)

## create test and training set
index <- sample(1:dim(spam)[1])
spamtrain <- spam[index[1:floor(dim(spam)[1]/2)], ]
spamtest <- spam[index[((ceiling(dim(spam)[1]/2)) + 1):dim(spam)[1]], ]

spamtrain$type <- as.factor(spamtrain$type)

model_0.05 <- kernlab::ksvm(type~., data=spamtrain, kernel="rbfdot", kpar=list(sigma=0.05), C=0.5)
model_0.05

conf_model_0.05 <- table(spamtrain[,58], predict(model_0.05, spamtrain[,-58]))
names(dimnames(conf_model_0.05)) <- c("Actual Test", "P2redicted Test")
caret::confusionMatrix(conf_model_0.05)

```

### 2. Use nested cross-validation to estimate the error of the model selection task described above. Use two folds for inner and outer cross-validation. Note that you only have to implement the outer cross-validation: The inner cross-validation can be performed by using the argument cross=2 when calling the function ksvm.

```{r}

```

